{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendations using Collaborative Filtering\n",
    "### - Dataset used: Group Lens 100K movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.io\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "#CONSTANTS\n",
    "\"\"\"Read data from files.\"\"\"\n",
    "DATAPATH = \"/Users/debojitkaushik/collaborative-filtering/ml-100k/\"\n",
    "Y_cols  = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(DATAPATH + 'u.data', sep = '\\t', encoding = 'latin-1', names = Y_cols).drop(\"timestamp\", 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Preprocessing/Formatting\n",
    "Create movies VS user matrix and ratings matrix. Create Y matrix and ratings matrix. Data is a dataframe with UserID|Movie_id|Rating format. Need to Vectorize this into a ratings matrix of MovieID vs UserID. Create the R matrix, which will have 1 if a user has rated or 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm, nu = len(data['item_id'].unique()), len(data['user_id'].unique())\n",
    "nf = 10\n",
    "\n",
    "# Initilize two matrices of size (nm, nu) and fill in the data.\n",
    "# # **Slow method. Need to optimize this. Will look into Pandas methods more. \n",
    "Y, ratings  = np.zeros((nm, nu)), np.zeros((nm, nu))\n",
    "for it, item in data.iterrows():\n",
    "    ratings[item['item_id']-1][item['user_id']-1] = 1.0\n",
    "    Y[item['item_id']-1][item['user_id']-1] = item['rating']\n",
    "print(\"Y:\" , Y.shape)\n",
    "print(\"R:\", ratings.shape)\n",
    "\n",
    "#OPTIONAL DATA SOURCE:\n",
    "# datafile = 'aux_data/ex8_movies.mat'\n",
    "# mat = scipy.io.loadmat( datafile )\n",
    "# Y = mat['Y']\n",
    "# ratings = mat['R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the data matrix.\n",
    "fig = plt.figure(figsize=(6,6*(nm/nu)))\n",
    "dummy = plt.imshow(Y)\n",
    "dummy = plt.colorbar()\n",
    "dummy = plt.ylabel('Movies (%d)'%nm,fontsize=20)\n",
    "dummy = plt.xlabel('Users (%d)'%nu,fontsize=20)\n",
    "#We can see the sparseness of the matrix as it is dominated by 0 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Cost Function and Gradient definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: loading Theta and X matrices. \n",
    "# mat = scipy.io.loadmat(\"data/ex8_movieParams.mat\")\n",
    "# theta, X, nf = mat['Theta'], mat['X'], mat['num_features']\n",
    "\n",
    "#Let's randomly initialize Theta and X matrices for starting points before we start learning.\n",
    "X, Theta = np.random.rand(nm, nf), np.random.rand(nu, nf)\n",
    "print(\"Shapes of Theta, X, Y, ratings:\", [i.shape for i in [Theta, X, Y, ratings]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method to flatten theta and X matrices into one vector'''\n",
    "def flatten_mat(X, Theta):\n",
    "    try:\n",
    "        return np.concatenate((X.flatten(), Theta.flatten()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "'''Method to extract X and theta from the flattened matrix and reshape.'''\n",
    "def unflatten(flattened_mat, mynu, mynm, mynf):\n",
    "    #X dimensions: nm*nf, theta dimensions: nu*nf\n",
    "    new_X = flattened_mat[:int(nm*nf)].reshape(mynm, mynf)\n",
    "    new_theta = flattened_mat[int(nm*nf):].reshape(mynu, mynf)\n",
    "    return new_X, new_theta\n",
    "\n",
    "'''Compute cost function'''\n",
    "def CFCost(params, myY, myR, mynu, mynm, mynf, myLambda = 0):\n",
    "    '''\n",
    "    args:\n",
    "        params: X+Theta (flattened vector)\n",
    "        myY: Movies VS Users matrix.\n",
    "        nu, nm, nf: No of user, no of movies, no of features\n",
    "    '''\n",
    "    #Extract X and theta from params which is a merged vector.\n",
    "    myX, myTheta = unflatten(params, mynu, mynm, mynf)\n",
    "    \n",
    "    #1/2∑((theta).T * X - Y)^2 + Regularization term\n",
    "    term1 = myX.dot(myTheta.T)\n",
    "    term1 = np.multiply(term1, myR)\n",
    "    cost = 0.5 * np.sum(np.square(term1 - myY))\n",
    "    \n",
    "    #Regularization factors. Twice, for lambda and for X.\n",
    "    #Regularizer: (λ/2) * (theta)^2 or (X)^2\n",
    "    cost += (myLambda/2) * (np.sum(np.square(myTheta)))\n",
    "    cost += (myLambda/2) * (np.sum(np.square(myX)))\n",
    "    return cost\n",
    "\n",
    "print(CFCost(flatten_mat(X, Theta), Y, ratings, nu, nm, nf))\n",
    "\n",
    "'''Gradient function. f'. '''\n",
    "def CFCostGrad(params, myR, myY, mynu, mynm, mynf, myLambda = 0):\n",
    "    '''\n",
    "    args:\n",
    "        params: X+Theta (flattened vector)\n",
    "        myY: Movies VS Users matrix with their ratings.\n",
    "        myR: Ratings binary matrix 0/1.\n",
    "        nu, nm, nf: No of user, no of movies, no of features\n",
    "    '''\n",
    "    #This is the partial derivative of the cost function with respect\n",
    "    #to theta and X.\n",
    "    #Unroll params into Theta and X and proceed with the derivative \n",
    "    #calculation.\n",
    "    myX, myTheta = unflatten(params, mynu, mynm, mynf)\n",
    "    term1 = myX.dot(myTheta.T)\n",
    "    term1 = np.multiply(term1, myR)\n",
    "    term1 = term1 - myY\n",
    "    X_grad = term1.dot(myTheta)\n",
    "    theta_grad = term1.T.dot(myX)\n",
    "\n",
    "    #Regularization\n",
    "    X_grad += (myLambda * myX)\n",
    "    theta_grad += (myLambda * myTheta)\n",
    "    return flatten_mat(X_grad, theta_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient(params, myR, myY, mynu, mynm, mynf, myLambda = 0):\n",
    "    epsilon = 0.0001\n",
    "    eps_vec = np.zeros(len(params))\n",
    "    myX, myTheta = unflatten(params, mynu, mynm, mynf)\n",
    "    grads = CFCostGrad(params, myR, myY, mynu, mynm, mynf, myLambda = 1.5)\n",
    "\n",
    "    for _ in range(10):\n",
    "        idx = np.random.randint(len(params))\n",
    "        eps_vec[idx] = epsilon\n",
    "        loss1 = CFCost(params-eps_vec, myY, myR, mynu, mynm, mynf, myLambda = 1.5)\n",
    "        loss2 = CFCost(params+eps_vec, myY, myR, mynu, mynm, mynf, myLambda = 1.5)\n",
    "        \n",
    "        mygrad = (loss2 - loss1) / (2*epsilon)\n",
    "        eps_vec[idx] = 0\n",
    "        print(mygrad, grads[idx], mygrad - grads[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking gradient function for lambda = 0:\")\n",
    "check_gradient(flatten_mat(X, Theta), ratings, Y, nu, nm, nf, myLambda = 0)\n",
    "print(\"\\nChecking gradient function for lambda = 1.5:\")\n",
    "check_gradient(flatten_mat(X, Theta), ratings, Y, nu, nm, nf, myLambda = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Learn parameters\n",
    "Add own ratings to the data to be trained on and perform minimzation/gradient descent on params(Theta+X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Learn parameters for recommendation\"\"\"\n",
    "#Add a vector for my own recommendations. \n",
    "my_ratings = np.zeros([nm,1])\n",
    "my_ratings[0]   = 4\n",
    "my_ratings[97]  = 2\n",
    "my_ratings[6]   = 3\n",
    "my_ratings[11]  = 5\n",
    "my_ratings[53]  = 4\n",
    "my_ratings[63]  = 5\n",
    "my_ratings[65]  = 3\n",
    "my_ratings[68]  = 5\n",
    "my_ratings[182] = 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354] = 5\n",
    "\n",
    "#Current nm, nu, nf are:\n",
    "print(\"Old nm, nu, nf\", nm, nu, nf)\n",
    "\n",
    "#Add my ratings vector to the matrices. \n",
    "Y = np.hstack((Y, my_ratings))\n",
    "myR = my_ratings > 0\n",
    "ratings = np.hstack((ratings, myR.astype(int)))\n",
    "print(Y.shape, ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm, nu = Y.shape\n",
    "X, Theta = np.random.rand(nm, nf), np.random.rand(nu, nf)\n",
    "my_flat_mat = flatten_mat(X, Theta)\n",
    "print(my_flat_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call minimizer.\n",
    "mylambda = 10.\n",
    "res = fmin_cg(CFCost, x0 = my_flat_mat, \\\n",
    "              fprime = CFCostGrad, args = (ratings, Y, nu, nm, nf, mylambda), \\\n",
    "              maxiter=50, disp = True, full_output = True)\n",
    "print(\"Prediction Matrix is:\", res[0], \", with shape:\", res[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nu, nm, nf)\n",
    "new_X, new_theta = unflatten(res[0], nu, nm, nf)\n",
    "pred_mat = new_X.dot(new_theta.T)\n",
    "\n",
    "def normalizeRatings(myY, myR):\n",
    "    # The mean is only counting movies that were rated\n",
    "    Ymean = np.sum(myY,axis=1)/np.sum(myR,axis=1)\n",
    "    Ymean = Ymean.reshape((Ymean.shape[0],1))\n",
    "    \n",
    "    return myY-Ymean, Ymean \n",
    "\n",
    "Ynorm, Ymean = normalizeRatings(Y, ratings)\n",
    "my_pred = pred_mat[:,-1] + Ymean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read movie list. \n",
    "movies = []\n",
    "with open(\"./aux_data/movie_ids.txt\") as f:\n",
    "    for item in f.read().split(\"\\n\"):\n",
    "        movies.append(\" \".join(item.split(\" \")[1:]))\n",
    "\n",
    "#Reverse sort my predictions and get the indexes. Then, get top 10 movies with those indexes.\n",
    "pred_idxs_sorted = np.argsort(my_pred)\n",
    "pred_idxs_sorted[:] = pred_idxs_sorted[::-1]\n",
    "\n",
    "\n",
    "print(\"\\033[1;34mTOP RECOMMENDATIONS FOR YOU:\\033[1;m\")\n",
    "for i in range(10):\n",
    "    print('\\033[1;33mPredicting rating for movie\\033[1;m', \\\n",
    "          str(my_pred[pred_idxs_sorted[i]])[:4],movies[pred_idxs_sorted[i]])\n",
    "\n",
    "my_ratings = my_ratings.flatten()\n",
    "print(\"\\n\\033[1;34mORIGINAL RATINGS BY YOU:\\033[1;m\")\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print('\\033[1;33mRated for movie\\033[1;m', my_ratings[i], movies[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
